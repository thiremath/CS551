# **MapReduce Project**

## **Project Overview**
This project implements a basic **MapReduce framework** in C, designed for efficient data processing tasks. The framework provides functionalities to split input data into smaller chunks, process them in parallel through a *map phase*, and aggregate intermediate results using a *reduce phase*. Two tasks are implemented as part of this project:

1. **Letter Counter**: Counts the frequency of each letter in the input data.
2. **Word Finder**: Identifies lines containing a specific word in the input data.

---

## **Key Features**
- Parallel processing with **forked processes** for map workers.
- Intermediate data management using temporary files.
- User-defined map and reduce functions for flexibility.
- Support for large input data with efficient data splitting.
- Error handling for file operations and process management.

---

## **Directory Structure**

```
├── mapreduce.c          # Core implementation of the MapReduce framework
├── usr_functions.c      # User-defined map and reduce functions
├── mapreduce.h          # Header file for MapReduce framework
├── usr_functions.h      # Header file for user-defined functions
├── common.h             # Common utilities and macros
├── Makefile             # Build automation for the project
├── input.txt            # Example input file
├── output.txt           # Output file containing final results
├── intermediate/        # Intermediate files generated by map workers
└── README.md            # Project documentation
```

---

## **Compilation**
To build the project, use the provided `Makefile`. Run the following command:
```bash
make
```
This will generate the executable binary for the project.

---

## **Usage**

### **Running the Framework**
The `mapreduce` function orchestrates the map and reduce operations. To use the framework, provide:
1. An input file path.
2. Number of splits for dividing the input data.
3. User-defined `map` and `reduce` functions.

Example usage:
```c
MAPREDUCE_SPEC spec = {
    .input_data_filepath = "input.txt",
    .split_num = 4,
    .map_func = letter_counter_map,
    .reduce_func = letter_counter_reduce,
    .usr_data = NULL
};

MAPREDUCE_RESULT result = {
    .filepath = "output.txt"
};

mapreduce(&spec, &result);
```

### **Tasks Implemented**
1. **Letter Counter**: Counts the frequency of each letter in the input data.
   - Input: Text file.
   - Output: Letter frequencies in `output.txt`.

2. **Word Finder**: Finds lines containing a specific word in the input data.
   - Input: Text file and target word (as `usr_data`).
   - Output: Lines containing the target word in `output.txt`.

---

## **Example Input and Output**

### **Input (`input.txt`)**
```
Hello World!
This is an example input text.
It contains multiple lines.
```

### **Output (Letter Counter)**
```
A 4
B 0
C 2
D 2
E 7
...
```

### **Output (Word Finder)** *(Target Word: `example`)*
```
This is an example input text.
```

---

## **Technical Highlights**
- **Data Splitting**: The input file is divided into chunks based on the specified number of splits.
- **Inter-Process Communication**: Temporary files are used for passing intermediate results from map workers to the reducer.
- **Error Handling**: Extensive error checks for file operations, memory allocation, and process management.
- **User Extensibility**: Customizable map and reduce functions to process diverse datasets.

---

## **How It Works**
1. **Map Phase**: 
   - Splits the input data into chunks.
   - Spawns child processes to process each chunk using the user-defined map function.
   - Writes intermediate results to temporary files.

2. **Reduce Phase**: 
   - Combines intermediate results from all map workers.
   - Uses the user-defined reduce function to produce the final output.

---

## **Contributions**
- **Tejas Hiremath** (B01038537): Complete implementation of the MapReduce framework and user-defined functions for letter counting and word finding.